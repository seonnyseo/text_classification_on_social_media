{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group3_Classification_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZrXvxj5MniW",
        "colab_type": "text"
      },
      "source": [
        "###1.Collecting Tweets through Twitter API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK96CvHjIPV3",
        "colab_type": "text"
      },
      "source": [
        "Using Twitter API, we can collect information tweets includes user information, date, and tweets. For this, install and import Twitter API first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvvC2NniLpg7",
        "colab_type": "code",
        "outputId": "834807d3-cce7-4bca-b5ba-55c727623757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install python-twitter\n",
        "import twitter\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-twitter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/2eb36853d8ca49a70482e2332aa5082e09b3180391671101b1612e3aeaf1/python_twitter-3.5-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from python-twitter) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from python-twitter) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from python-twitter) (1.2.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->python-twitter) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->python-twitter) (3.1.0)\n",
            "Installing collected packages: python-twitter\n",
            "Successfully installed python-twitter-3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EhK2nB8O9eI",
        "colab_type": "text"
      },
      "source": [
        "import keys.py file that contains twitter API user information to collect tweets from twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ea7cGVfL57X",
        "colab_type": "code",
        "outputId": "b0be8ab1-5aa7-4379-ffbc-efa0c9592b38",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('mylib.py','wb').write(src)\n",
        "import mylib\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0f0b2c9-0a24-419e-9ca3-52c9a54154e1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f0f0b2c9-0a24-419e-9ca3-52c9a54154e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving keys.py to keys.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwD9GCeTRa2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keys\n",
        "api = twitter.Api(consumer_key = keys.consumer_key,\n",
        "                 consumer_secret = keys.consumer_secret,\n",
        "                 access_token_key = keys.access_token,\n",
        "                 access_token_secret = keys.access_token_secret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOllbIdQMIq2",
        "colab_type": "code",
        "outputId": "bf42c762-29a5-48c1-dd96-7950cd7ba420",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "  name = fn, length = len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c423007e-c49b-47fa-866e-6092b97d5ca3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c423007e-c49b-47fa-866e-6092b97d5ca3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving drug_safety_data.txt to drug_safety_data.txt\n",
            "User uploaded file \"drug_safety_data.txt\" with length 185065 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gXFSyslPZzi",
        "colab_type": "text"
      },
      "source": [
        "Tweets ids and twitter user ids are in 'drug_safety_data.txt' file. \n",
        "\n",
        "1. Collect tweets information that we will refer through twitter API\n",
        "2. The data are stored as json format\n",
        "3. Text in below shows how it is constructed \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNwJFUc1KlHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k7HqmJLMP5h",
        "colab_type": "code",
        "outputId": "c8e4b531-1ed2-4363-9354-d7c21e7169df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "drugTweets = pd.read_csv('drug_safety_data.txt', delimiter = '\\t', header = None, names = ['tweet_id', 'twitter_user_id', 'abuse'])\n",
        "drugTweets = drugTweets.drop_duplicates()\n",
        "drugTweets_text = api.GetStatuses(drugTweets.tweet_id)\n",
        "txts = []\n",
        "for tweet in drugTweets_text:\n",
        "  txts.append(json.loads(json.dumps(tweet._json)))\n",
        "txts[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contributors': None,\n",
              " 'coordinates': None,\n",
              " 'created_at': 'Sun May 12 18:08:41 +0000 2013',\n",
              " 'entities': {'hashtags': [], 'symbols': [], 'urls': [], 'user_mentions': []},\n",
              " 'favorite_count': 0,\n",
              " 'favorited': False,\n",
              " 'geo': None,\n",
              " 'id': 333644914913079296,\n",
              " 'id_str': '333644914913079296',\n",
              " 'in_reply_to_screen_name': None,\n",
              " 'in_reply_to_status_id': None,\n",
              " 'in_reply_to_status_id_str': None,\n",
              " 'in_reply_to_user_id': None,\n",
              " 'in_reply_to_user_id_str': None,\n",
              " 'is_quote_status': False,\n",
              " 'lang': 'en',\n",
              " 'place': None,\n",
              " 'retweet_count': 0,\n",
              " 'retweeted': False,\n",
              " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
              " 'text': 'i know for a FACT that alcohol does not deplete the seroquel levels in your blood, YET HERE WE ARE',\n",
              " 'truncated': False,\n",
              " 'user': {'contributors_enabled': False,\n",
              "  'created_at': 'Fri Dec 24 03:45:56 +0000 2010',\n",
              "  'default_profile': False,\n",
              "  'default_profile_image': False,\n",
              "  'description': 'revive prime suspect (2011 - 2012)',\n",
              "  'entities': {'description': {'urls': []},\n",
              "   'url': {'urls': [{'display_url': 'nastyratched.tumblr.com',\n",
              "      'expanded_url': 'http://nastyratched.tumblr.com',\n",
              "      'indices': [0, 23],\n",
              "      'url': 'https://t.co/Ce4IWf7ziQ'}]}},\n",
              "  'favourites_count': 55542,\n",
              "  'follow_request_sent': False,\n",
              "  'followers_count': 178,\n",
              "  'following': False,\n",
              "  'friends_count': 570,\n",
              "  'geo_enabled': True,\n",
              "  'has_extended_profile': False,\n",
              "  'id': 230052171,\n",
              "  'id_str': '230052171',\n",
              "  'is_translation_enabled': False,\n",
              "  'is_translator': False,\n",
              "  'lang': None,\n",
              "  'listed_count': 4,\n",
              "  'location': 'perth, western australia',\n",
              "  'name': 'john s. lithgoat',\n",
              "  'notifications': False,\n",
              "  'profile_background_color': 'CCCCCC',\n",
              "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_tile': True,\n",
              "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/230052171/1516295902',\n",
              "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1054691338610913280/oINSEFmk_normal.jpg',\n",
              "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1054691338610913280/oINSEFmk_normal.jpg',\n",
              "  'profile_link_color': '999999',\n",
              "  'profile_sidebar_border_color': '000000',\n",
              "  'profile_sidebar_fill_color': '333333',\n",
              "  'profile_text_color': '666666',\n",
              "  'profile_use_background_image': False,\n",
              "  'protected': False,\n",
              "  'screen_name': 'pants2match',\n",
              "  'statuses_count': 33777,\n",
              "  'time_zone': None,\n",
              "  'translator_type': 'none',\n",
              "  'url': 'https://t.co/Ce4IWf7ziQ',\n",
              "  'utc_offset': None,\n",
              "  'verified': False}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "435Tebv7QW8f",
        "colab_type": "text"
      },
      "source": [
        "From the json format, take out necessary information such as user_ids and texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tjx3WSJMgD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = []\n",
        "text = []\n",
        "for line in txts:\n",
        "  ids.append(line['id'])\n",
        "  text.append(line['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-qYCV8YMwXj",
        "colab_type": "text"
      },
      "source": [
        "###2.Text pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gC5uc2DJPZW",
        "colab_type": "text"
      },
      "source": [
        "Tweets were written in the informal language in most cases, and included reserved words related to Twitter. To improve machine learning models performance, it is required to clean unnecessary text up to teach models clearly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0HksoeyXqqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7_ZHDBFOQLb",
        "colab_type": "text"
      },
      "source": [
        "####1.Remove Twitter reserved word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO8mYvppM1g1",
        "colab_type": "code",
        "outputId": "e14ff7aa-defd-4c10-ba1e-e5f8508beaa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7946 sha256=d7bdb1b8e01bb419d1466c4c846844d6f8e02e65bf0986cc5814632499f7228f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5RRQ9T5Oerk",
        "colab_type": "text"
      },
      "source": [
        "tweet-preprocessor library supports to remove these text.\n",
        "\n",
        "\n",
        "1.   URLs\n",
        "2.   Hashtags\n",
        "3.   Mentions\n",
        "4.   Reserved words (RT, FAV)\n",
        "5.   Emojis\n",
        "6.   Smileys\n",
        "7.   Number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xyfQn5QM7D0",
        "colab_type": "code",
        "outputId": "34c427e0-6a42-4e22-9275-83e55bc82239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "text_clean = []\n",
        "for line in text:\n",
        "  text_clean.append(p.clean(line))\n",
        "print('Before : {}'.format(text[1]))\n",
        "print('After  : {}'.format(text_clean[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before : @Scribble_Dragon 50 mg Seroquel with my ‘normal’ 60 mg Lovan and 750 mcg Clonazepam.\n",
            "After  : mg Seroquel with my ‘normal’ mg Lovan and mcg Clonazepam.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7-K97IFP2YX",
        "colab_type": "text"
      },
      "source": [
        "After cleaning twitter reserved words, put this on the data frame that includes tweet_id, user_id and classfication label information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO80Q22pM_HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_w_text = pd.DataFrame(list(zip(ids, text_clean)), columns = ['tweet_id', 'text_text'])\n",
        "drugTweets_df = pd.merge(tweets_w_text, drugTweets, on = 'tweet_id', how = 'inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ZxZ-bqOlUX",
        "colab_type": "text"
      },
      "source": [
        "####2.Stopwords / Lowercase / Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ULizQcYShT",
        "colab_type": "text"
      },
      "source": [
        "Besides removing Twitter words, we can remove stopwords that would not give important information and lowercase every text for avoiding counting same words several times. Also, we decide to apply stemming to reduce inflected words to their word stem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GrnyPFERWvr",
        "colab_type": "code",
        "outputId": "a90592cd-eb2c-4f86-f789-6c37a814218e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "femVI2A9dujC",
        "colab_type": "text"
      },
      "source": [
        "'fix_text' function includes removing stopwords, stemming, lowercasing and removing special characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3YjCNv6R1Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "snow = nltk.stem.SnowballStemmer('english')\n",
        "\n",
        "def fix_Text(text):\n",
        "\tletters_only = re.sub(\"[^a-zA-Z]\",\" \", str(text))\n",
        "\twords=letters_only.lower().split()\n",
        "\tmeaningful=[snow.stem(word) for word in words if word not in stop_words]\n",
        "\treturn(\" \".join(meaningful))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbDAvYOASWKP",
        "colab_type": "code",
        "outputId": "56cb10a2-fe84-4fe3-89f6-1acd034cdf0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_resp = drugTweets_df[\"text_text\"].size\n",
        "print(\"Before : {}\".format(drugTweets_df['text_text'][2]))\n",
        "clean_text = []\n",
        "for i in range(0,num_resp):\n",
        "\tclean_text.append(fix_Text(drugTweets_df[\"text_text\"][i]))\n",
        "\n",
        "print(\"After : {}\".format(clean_text[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before : SEVEN missed calls? get you're seroquel mg lowered. you're getting ridiculous\n",
            "After : seven miss call get seroquel mg lower get ridicul\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZeK41hqe3kh",
        "colab_type": "text"
      },
      "source": [
        "Also we found that twitter users use two words for one medicine such and also they type energy drink 'red bull' or 'redbull'. We thought it is reasonable to count these words together. Also, even we removed special characters, broken codes are still in text such as 'amp', 'lt,' and 'gt' because thoese are alphabet characters. So we made a function that change specific words, and remove the broken codes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kapRuicRY_Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = {'quetiapin' : 'seroquel', 'oxycontin' : 'oxycodone', 'red bull' : 'redbull', 'amp':'', 'lt':'', 'gt':''}\n",
        "\n",
        "def change_word(text):\n",
        "  for key in list(word_list.keys()):\n",
        "    if key in text:\n",
        "      text = text.replace(key, word_list[key])\n",
        "\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOsW38i7ZCnF",
        "colab_type": "code",
        "outputId": "878e7062-9749-46cc-8621-a70556dd84e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Before : {}\".format(clean_text[5]))\n",
        "for i in range(num_resp):\n",
        "  clean_text[i] = change_word(clean_text[i])\n",
        "\n",
        "print(\"After : {}\".format(clean_text[5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before : antipsychot quetiapin sedat olanzapin risperidon aripiprazol lithium augment agent\n",
            "After : antipsychot seroquel sedat olanzapin risperidon aripiprazol lithium augment agent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr8rugwJYCNk",
        "colab_type": "text"
      },
      "source": [
        "###3.Document - Term representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_KmD0Yw7Hw0",
        "colab_type": "text"
      },
      "source": [
        "In order to classify tweets by machine learning models, we need to create a document-term representation. Numbers in the matrix represent how important a word is to a document in a collection or corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_R-24u4Yo9l",
        "colab_type": "text"
      },
      "source": [
        "##### 1.Term Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALacM_0u9IAp",
        "colab_type": "text"
      },
      "source": [
        "Using by CountVectorizer function, we can tokenize and count the frequency of words in tweets. After it, fit_transform module creats a Document-Term matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU2a4O4qYFj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "836QJ71WYdNC",
        "colab_type": "code",
        "outputId": "32779586-8088-483a-9fa2-9b8adb1d07a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tfVectorizer=CountVectorizer()\n",
        "tfdtm= tfVectorizer.fit_transform(clean_text)\n",
        "tfVectorizer.get_feature_names()[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abbi', 'abid', 'abil', 'abilifi', 'abl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVWUL-x5Yr5p",
        "colab_type": "text"
      },
      "source": [
        "#### 2.Term Frequency - Inverse Document Frequency (Feature Selection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC2it_LD-qO1",
        "colab_type": "text"
      },
      "source": [
        "The frequency of words does not tell us how the words important, because some not important words such as 'I', 'the', 'a' would frequently appear than other terms. Term Frequency - Inverse Document Frequency value represents priority by the number of appearance in the document / the number of occurrence in the corpus. \n",
        "\n",
        "TfidfVectorizer module helps create tfidf matrix and set the minimum number of appearance. After creating the counting vector, convert it to data frame that we are going to use it for classification modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkx3Vc__YmGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1VocJfws7Ea",
        "colab_type": "text"
      },
      "source": [
        "We then created 3 datasets where only the terms that appeared a minimum of 20, 30 and 50 times respectively would be included. With the minimum term appearance of 20, 226 features were retained for a minimum of 30 terms, 137 features were retained, and with a minimum of 50 term appearances, 67 features were retained. \n",
        "\n",
        "We evaluated the result of each frequency before, and 30 reveals the best performance. Thus, we decide to set minimum frequency of words ad 30 here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUzBnLvDYzcb",
        "colab_type": "code",
        "outputId": "41b92354-4918-4a24-84cb-23ba06b47c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tfidfVectorizer=TfidfVectorizer(min_df=30)\n",
        "tfidfdtm = tfidfVectorizer.fit_transform(clean_text)\n",
        "tfidfVectorizer.get_feature_names()[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['actual', 'adderal', 'addict', 'also', 'ask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsXRmtoHespq",
        "colab_type": "code",
        "outputId": "667c36d3-3826-43f5-f5e4-b9e9e5429b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "tfidf_df = pd.DataFrame(tfidfdtm.toarray(), columns=tfidfVectorizer.get_feature_names())\n",
        "tfidf_df[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>adderal</th>\n",
              "      <th>addict</th>\n",
              "      <th>also</th>\n",
              "      <th>ask</th>\n",
              "      <th>ass</th>\n",
              "      <th>back</th>\n",
              "      <th>bad</th>\n",
              "      <th>bed</th>\n",
              "      <th>best</th>\n",
              "      <th>better</th>\n",
              "      <th>call</th>\n",
              "      <th>caus</th>\n",
              "      <th>coffe</th>\n",
              "      <th>come</th>\n",
              "      <th>could</th>\n",
              "      <th>day</th>\n",
              "      <th>doctor</th>\n",
              "      <th>done</th>\n",
              "      <th>dose</th>\n",
              "      <th>drink</th>\n",
              "      <th>drug</th>\n",
              "      <th>eat</th>\n",
              "      <th>effect</th>\n",
              "      <th>even</th>\n",
              "      <th>ever</th>\n",
              "      <th>everi</th>\n",
              "      <th>feel</th>\n",
              "      <th>final</th>\n",
              "      <th>find</th>\n",
              "      <th>first</th>\n",
              "      <th>focus</th>\n",
              "      <th>friend</th>\n",
              "      <th>fuck</th>\n",
              "      <th>gave</th>\n",
              "      <th>get</th>\n",
              "      <th>give</th>\n",
              "      <th>go</th>\n",
              "      <th>gonna</th>\n",
              "      <th>good</th>\n",
              "      <th>...</th>\n",
              "      <th>shit</th>\n",
              "      <th>sinc</th>\n",
              "      <th>sleep</th>\n",
              "      <th>someon</th>\n",
              "      <th>someth</th>\n",
              "      <th>start</th>\n",
              "      <th>stay</th>\n",
              "      <th>still</th>\n",
              "      <th>stop</th>\n",
              "      <th>studi</th>\n",
              "      <th>sure</th>\n",
              "      <th>surgeri</th>\n",
              "      <th>take</th>\n",
              "      <th>taken</th>\n",
              "      <th>talk</th>\n",
              "      <th>tell</th>\n",
              "      <th>thank</th>\n",
              "      <th>thing</th>\n",
              "      <th>think</th>\n",
              "      <th>thought</th>\n",
              "      <th>time</th>\n",
              "      <th>today</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>tonight</th>\n",
              "      <th>took</th>\n",
              "      <th>tri</th>\n",
              "      <th>two</th>\n",
              "      <th>use</th>\n",
              "      <th>wake</th>\n",
              "      <th>wanna</th>\n",
              "      <th>want</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>well</th>\n",
              "      <th>without</th>\n",
              "      <th>work</th>\n",
              "      <th>would</th>\n",
              "      <th>xanax</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.532974</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.696834</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.69535</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.269218</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.448937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.445602</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.747859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.45356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.444197</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.46185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.378680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 134 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   actual  adderal  addict  also  ...     would  xanax  yeah      year\n",
              "0     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "1     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "2     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "3     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "4     0.0  0.16467     0.0   0.0  ...  0.000000    0.0   0.0  0.448937\n",
              "5     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "6     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "7     0.0  0.00000     0.0   0.0  ...  0.747859    0.0   0.0  0.000000\n",
              "8     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "9     0.0  0.00000     0.0   0.0  ...  0.000000    0.0   0.0  0.000000\n",
              "\n",
              "[10 rows x 134 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnF0JAT4AyEw",
        "colab_type": "code",
        "outputId": "112b21db-b498-4d81-bf73-b7e9b9acb793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "drugTweets_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text_text</th>\n",
              "      <th>twitter_user_id</th>\n",
              "      <th>abuse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>333644914913079296</td>\n",
              "      <td>i know for a FACT that alcohol does not deplet...</td>\n",
              "      <td>230052171</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>344825926342832128</td>\n",
              "      <td>mg Seroquel with my ‘normal’ mg Lovan and mcg ...</td>\n",
              "      <td>179074771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>333854289023864832</td>\n",
              "      <td>SEVEN missed calls? get you're seroquel mg low...</td>\n",
              "      <td>333099736</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>344606561873833985</td>\n",
              "      <td>there's a fella on my Facebook who is asking t...</td>\n",
              "      <td>464202509</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>341947615853813761</td>\n",
              "      <td>you take vyvanse? I was on that stuff for like...</td>\n",
              "      <td>90304006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>328655421256654849</td>\n",
              "      <td>antipsychotics: quetiapine (sedation); olanzap...</td>\n",
              "      <td>1371093139</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>333735685406224385</td>\n",
              "      <td>I take quetiapine and it's supposed to just re...</td>\n",
              "      <td>38919907</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>344937940146855937</td>\n",
              "      <td>Seroquel is pretty heavy stuff. I would've tho...</td>\n",
              "      <td>185070700</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>342112352130449409</td>\n",
              "      <td>Tell me why this kid just gave me six seroquel...</td>\n",
              "      <td>345065773</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>341680382179160065</td>\n",
              "      <td>look at the tweet near that one. I refuse to t...</td>\n",
              "      <td>38971420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>332223414595117056</td>\n",
              "      <td>Just about dead, think it's bedtime.. Fuck you...</td>\n",
              "      <td>52782775</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>333733798787284992</td>\n",
              "      <td>I may not have weed, but I do have seroquel I ...</td>\n",
              "      <td>1373158400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>340530953015402497</td>\n",
              "      <td>I hate to hear that. Taking seroquel is like s...</td>\n",
              "      <td>323940583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>343565496320417792</td>\n",
              "      <td>Im bout to slip some of my seroquel into her d...</td>\n",
              "      <td>369114238</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>344277608759975936</td>\n",
              "      <td>I prescribed quetiapine to my obese patient al...</td>\n",
              "      <td>46989098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>341178969535705088</td>\n",
              "      <td>&amp;lt; Seroquel - at high doses its for psychoti...</td>\n",
              "      <td>386313872</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>340274216471515136</td>\n",
              "      <td>but I WOULD use it if I were asleep on quetiap...</td>\n",
              "      <td>1123283994</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>329007984845926402</td>\n",
              "      <td>were on the same meds haha serequol and quetia...</td>\n",
              "      <td>857673764</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>329391569620856833</td>\n",
              "      <td>they mentioned quetiapine for me ages ago, but...</td>\n",
              "      <td>586045105</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>342143067169632256</td>\n",
              "      <td>I been knocked the fuck out yo. Like I took a ...</td>\n",
              "      <td>190770320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>343814505706430464</td>\n",
              "      <td>Right, got a date with Ms Quetiapine and Law A...</td>\n",
              "      <td>18332340</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>341026211218194432</td>\n",
              "      <td>am and the quetiapine has failed to sedate me</td>\n",
              "      <td>1317291756</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>340134027535204352</td>\n",
              "      <td>\"I DONT TAKE MEDS IN THE MORNING! VITAMINS? SE...</td>\n",
              "      <td>425214012</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>341242496321482753</td>\n",
              "      <td>(Triggering) So... I'm taking quetiapine and t...</td>\n",
              "      <td>562490916</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>330278165765312512</td>\n",
              "      <td>I'll be on mg of Quetiapine for the next night...</td>\n",
              "      <td>273421529</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>344351386542174208</td>\n",
              "      <td>okay i took the seroquel and i am resisting th...</td>\n",
              "      <td>15147617</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>344359166556639232</td>\n",
              "      <td>: lemme suck the seroquel residue off your fin...</td>\n",
              "      <td>31061240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>329560087259672576</td>\n",
              "      <td>Do you know what Meds are R for bipolar depres...</td>\n",
              "      <td>158119360</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>340152385051688960</td>\n",
              "      <td>ur so ignorant im at the hospital right now to...</td>\n",
              "      <td>1429295593</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>340601194655395840</td>\n",
              "      <td>Just seeing whats occurring on twitter. .while...</td>\n",
              "      <td>1449942523</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945</th>\n",
              "      <td>541062704102785024</td>\n",
              "      <td>I tried air before Seroquel but when I found i...</td>\n",
              "      <td>502126127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2946</th>\n",
              "      <td>541855078920228864</td>\n",
              "      <td>\"Because people with ADD/ADHD don't deserve to...</td>\n",
              "      <td>449961812</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2947</th>\n",
              "      <td>540597014640095232</td>\n",
              "      <td>Haloti Ngata got suspended games for taking Ad...</td>\n",
              "      <td>542355930</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2948</th>\n",
              "      <td>540681647482368000</td>\n",
              "      <td>half you niggas be thinking yall popping zans ...</td>\n",
              "      <td>2325682592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2949</th>\n",
              "      <td>540966927993028608</td>\n",
              "      <td>was reaching for a bottle of oxycodone pills w...</td>\n",
              "      <td>2904639999</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2950</th>\n",
              "      <td>541371565003526145</td>\n",
              "      <td>Officers seized total of Oxycodone pills — -mg...</td>\n",
              "      <td>942487562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2951</th>\n",
              "      <td>540763703340056576</td>\n",
              "      <td>\": I'm going to name my first born oxycodone b...</td>\n",
              "      <td>34191550</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>540919065385390080</td>\n",
              "      <td>seroquel is certainly powerful. i took a half ...</td>\n",
              "      <td>280230553</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2953</th>\n",
              "      <td>541758583063343104</td>\n",
              "      <td>AndisGraudins RCT IbuprofPanadol w or w/out co...</td>\n",
              "      <td>980098682</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2954</th>\n",
              "      <td>540743596639780864</td>\n",
              "      <td>I swore this oxycodone would've knocked me out...</td>\n",
              "      <td>188150281</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2955</th>\n",
              "      <td>540596388074373120</td>\n",
              "      <td>Oxycodone also numbs the pain when watford los...</td>\n",
              "      <td>302174491</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2956</th>\n",
              "      <td>541739968754761728</td>\n",
              "      <td>hey hey hey hey hey the oxycodone is startting...</td>\n",
              "      <td>525375457</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2957</th>\n",
              "      <td>541131854636916736</td>\n",
              "      <td>The dreams I have while on Oxycodone are inane...</td>\n",
              "      <td>1154416777</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2958</th>\n",
              "      <td>540679886307065857</td>\n",
              "      <td>killed for holding a bottle of oxycodone pills.</td>\n",
              "      <td>36519411</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2959</th>\n",
              "      <td>541547716220698624</td>\n",
              "      <td>if I take my seroquel I sleep too much and if ...</td>\n",
              "      <td>421696198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2960</th>\n",
              "      <td>541017124559675393</td>\n",
              "      <td>thank you seroquel for making me sleep for hou...</td>\n",
              "      <td>1549264729</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2961</th>\n",
              "      <td>541856612529750018</td>\n",
              "      <td>fuck that guy. Is Adderall really cheaper than...</td>\n",
              "      <td>939762660</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2962</th>\n",
              "      <td>541722116052111360</td>\n",
              "      <td>\": Took adderall to help me focus on school bu...</td>\n",
              "      <td>40339249</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2963</th>\n",
              "      <td>540634933018898432</td>\n",
              "      <td>We still don't know if the pill bottle w/ oxyc...</td>\n",
              "      <td>28476383</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2964</th>\n",
              "      <td>541057303781576704</td>\n",
              "      <td>playing cards against humanity on seroquel can...</td>\n",
              "      <td>221562659</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>541556536867168256</td>\n",
              "      <td>I'm too high on oxycodone for my tooth ache to...</td>\n",
              "      <td>22197146</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2966</th>\n",
              "      <td>541870151751065600</td>\n",
              "      <td>The kind of night where I feel like I need Add...</td>\n",
              "      <td>1686924378</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2967</th>\n",
              "      <td>541984407578349568</td>\n",
              "      <td>Lol! Lambert must be on a cocktail of Xanax, S...</td>\n",
              "      <td>621018967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2968</th>\n",
              "      <td>542018327359406080</td>\n",
              "      <td>What is the most potent form and delivery meth...</td>\n",
              "      <td>170357723</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2969</th>\n",
              "      <td>542019095353622528</td>\n",
              "      <td>Adderall is gonna be my new best friend. Along...</td>\n",
              "      <td>430195866</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2970</th>\n",
              "      <td>541858163289784320</td>\n",
              "      <td>I'm hip, but that's what my other tweet is abo...</td>\n",
              "      <td>288784938</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2971</th>\n",
              "      <td>542031072171933697</td>\n",
              "      <td>My body already hates me for the copious amoun...</td>\n",
              "      <td>360382242</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2972</th>\n",
              "      <td>541866635964203009</td>\n",
              "      <td>Adderall will make you check twitter plus time...</td>\n",
              "      <td>281287390</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2973</th>\n",
              "      <td>541998263256485890</td>\n",
              "      <td>finals week tip: make sure u poop, pee, and ea...</td>\n",
              "      <td>867182059</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2974</th>\n",
              "      <td>541886694111604736</td>\n",
              "      <td>My favorite thing about adderall is how it kee...</td>\n",
              "      <td>777096356</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2975 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                tweet_id  ... abuse\n",
              "0     333644914913079296  ...     0\n",
              "1     344825926342832128  ...     0\n",
              "2     333854289023864832  ...     0\n",
              "3     344606561873833985  ...     1\n",
              "4     341947615853813761  ...     0\n",
              "5     328655421256654849  ...     0\n",
              "6     333735685406224385  ...     0\n",
              "7     344937940146855937  ...     0\n",
              "8     342112352130449409  ...     0\n",
              "9     341680382179160065  ...     0\n",
              "10    332223414595117056  ...     0\n",
              "11    333733798787284992  ...     1\n",
              "12    340530953015402497  ...     0\n",
              "13    343565496320417792  ...     1\n",
              "14    344277608759975936  ...     0\n",
              "15    341178969535705088  ...     0\n",
              "16    340274216471515136  ...     0\n",
              "17    329007984845926402  ...     0\n",
              "18    329391569620856833  ...     0\n",
              "19    342143067169632256  ...     0\n",
              "20    343814505706430464  ...     0\n",
              "21    341026211218194432  ...     0\n",
              "22    340134027535204352  ...     0\n",
              "23    341242496321482753  ...     0\n",
              "24    330278165765312512  ...     0\n",
              "25    344351386542174208  ...     0\n",
              "26    344359166556639232  ...     1\n",
              "27    329560087259672576  ...     0\n",
              "28    340152385051688960  ...     0\n",
              "29    340601194655395840  ...     0\n",
              "...                  ...  ...   ...\n",
              "2945  541062704102785024  ...     0\n",
              "2946  541855078920228864  ...     0\n",
              "2947  540597014640095232  ...     0\n",
              "2948  540681647482368000  ...     1\n",
              "2949  540966927993028608  ...     0\n",
              "2950  541371565003526145  ...     0\n",
              "2951  540763703340056576  ...     0\n",
              "2952  540919065385390080  ...     0\n",
              "2953  541758583063343104  ...     0\n",
              "2954  540743596639780864  ...     0\n",
              "2955  540596388074373120  ...     0\n",
              "2956  541739968754761728  ...     0\n",
              "2957  541131854636916736  ...     0\n",
              "2958  540679886307065857  ...     0\n",
              "2959  541547716220698624  ...     0\n",
              "2960  541017124559675393  ...     0\n",
              "2961  541856612529750018  ...     0\n",
              "2962  541722116052111360  ...     0\n",
              "2963  540634933018898432  ...     1\n",
              "2964  541057303781576704  ...     0\n",
              "2965  541556536867168256  ...     0\n",
              "2966  541870151751065600  ...     0\n",
              "2967  541984407578349568  ...     0\n",
              "2968  542018327359406080  ...     0\n",
              "2969  542019095353622528  ...     0\n",
              "2970  541858163289784320  ...     1\n",
              "2971  542031072171933697  ...     1\n",
              "2972  541866635964203009  ...     0\n",
              "2973  541998263256485890  ...     1\n",
              "2974  541886694111604736  ...     0\n",
              "\n",
              "[2975 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlY9KgvTAh1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_df['abused'] = drugTweets_df.abuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HgDG9_2HlXx",
        "colab_type": "text"
      },
      "source": [
        "###4.Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ELTW7uuAtsy",
        "colab_type": "text"
      },
      "source": [
        "Data set for modeling is made through text pre-processing and creating a tf-idf matrix. In this part, we will focus on how to make classfication models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1X-voMAqbt",
        "colab_type": "text"
      },
      "source": [
        "####1.Import classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlS5E4GtBa-7",
        "colab_type": "text"
      },
      "source": [
        "Importing classification model packages.\n",
        "\n",
        "We will train KNN, SVM, Naive Bayes, and Decision tree models, and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qcSLT0BGVL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC  \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSruCEdsIOx1",
        "colab_type": "text"
      },
      "source": [
        "####2.Load DTM File and split as train & test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3QI-rmyEN52",
        "colab_type": "text"
      },
      "source": [
        "Use a tf-idf matrix that we made above as dataset.\n",
        "\n",
        "1.   Take a label column in dataset as y.\n",
        "2.   Split dataset as training and test set. (Training 80% / Test 20%)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64U3ocCrfZfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tfidf_df.drop('abused', axis = 1)\n",
        "y = tfidf_df.abused\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-M34b4pG74r",
        "colab_type": "text"
      },
      "source": [
        "Check how many abuse tweets do we have on our dataset.\n",
        "\n",
        "0 is not abused one, and 1 is abused. So, we have about 15% of tweets that were labeled as abused.\n",
        "\n",
        "We can tell it is imbalanced dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Xyaih9X5Km",
        "colab_type": "code",
        "outputId": "c423f95b-5e56-4fab-e3b7-68c9b46e169a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tfidf_df.abused.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2534\n",
              "1     441\n",
              "Name: abused, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNero_vJL1F",
        "colab_type": "text"
      },
      "source": [
        "####3.Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCE4QsLJKZdz",
        "colab_type": "text"
      },
      "source": [
        "If we train models with imbalanced data, the models will be biased to predict majority class which is not aligned to the purpose of this study. In order to resolve this problem, we executed resamplings to make dataset balanced.\n",
        "\n",
        "We will apply 3 types of resampling and pick the best one.\n",
        "\n",
        "\n",
        "1. Random Over Sampling\n",
        "2. Random Under Sampling\n",
        "3. SMOTE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojg9w34LJlh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUS9RLABL4zi",
        "colab_type": "text"
      },
      "source": [
        "Oversampling  (X_train_up, y_train_up)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0l6bKXmL5z1",
        "colab_type": "code",
        "outputId": "1da1d82b-dfbc-44ed-c40e-0cda0918203c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ros = RandomOverSampler(random_state = 123)\n",
        "X_train_up, y_train_up = ros.fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_train_up).items()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 2029), (1, 2029)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Oavkn-MHTU",
        "colab_type": "text"
      },
      "source": [
        "SMOTE (X_train_SMOTE, y_train_SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL4nDKf5MJOI",
        "colab_type": "code",
        "outputId": "5dd4f8e2-125f-4ff5-9689-cf4b1cbcbd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_SMOTE, y_train_SMOTE = SMOTE().fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_train_SMOTE).items()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 2029), (1, 2029)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFMekfjxMTAm",
        "colab_type": "text"
      },
      "source": [
        "Undersampling (X_train_under, y_train_under)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlqqvz_WMSl2",
        "colab_type": "code",
        "outputId": "31d0ac7f-44df-4516-ce61-685f45384d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rus = RandomUnderSampler(random_state = 123)\n",
        "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_train_under).items()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 351), (1, 351)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TACqgO5KVHjJ",
        "colab_type": "text"
      },
      "source": [
        "####4.Train and evaluate \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clVrztbsXgbD",
        "colab_type": "text"
      },
      "source": [
        "With oversampled data, we will train models, test on those and compare which classification model shows the best performance. \n",
        "\n",
        "Here is three functions that we made to work done easily.\n",
        "\n",
        "\n",
        "*   fit_models - Training four models(KNN, SVM, Decision Tree, Naive Bayes) with oversampled data.\n",
        "*   compare_model - Predict abused tweets based on the models trained on fit_models function.\n",
        "*   print_result - Put training and test result as inputs and compare models peformance comfortably.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHymjemcJizx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_models(X_train, y_train):\n",
        "  \n",
        "  knn = KNeighborsClassifier()\n",
        "  svm = SVC(kernel = 'linear', random_state = 123)\n",
        "  dt = DecisionTreeClassifier(random_state = 123)\n",
        "  nb = GaussianNB()\n",
        "\n",
        "  _models = [knn, svm, dt, nb]\n",
        "  \n",
        "  classifiers = []\n",
        "  for classifier in _models:\n",
        "    classifier.fit(X = X_train, y = y_train)\n",
        "    classifiers.append(classifier)\n",
        "    \n",
        "  return classifiers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8EdbLJJKGzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_models(classifiers, X, y):\n",
        "\n",
        "  reports = []\n",
        "  matrix = []\n",
        "  \n",
        "  for _classi in classifiers:\n",
        "    _predicted = _classi.predict(X = X)\n",
        "    _report = metrics.classification_report(y, _predicted)\n",
        "    _matrix = metrics.confusion_matrix(y, _predicted)\n",
        "    \n",
        "    reports.append(_report)\n",
        "    matrix.append(_matrix)\n",
        "  \n",
        "  return (reports, matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNKflwAlGkVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_result(models, train_report, test_report):\n",
        "  \n",
        "  for model, train, test in zip(models, train_report, test_report):\n",
        "    print('{:_<112}'.format(model))\n",
        "    print('{}  {}  {}'.format('train',' ' * 55, 'test'))\n",
        "    \n",
        "    train_lines = train.split('\\n')\n",
        "    test_lines = test.split('\\n')\n",
        "    \n",
        "    for train_line, test_line in zip(train_lines, test_lines):\n",
        "      print(train_line + ' ' * 5 + test_line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QQn7e2GtSrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = ['KNN', 'SVM_Linear', 'DecisionTree','NaiveBayesian']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaLRj8VSudh7",
        "colab_type": "text"
      },
      "source": [
        "Oversampling Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oOM-KA3Nh8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_models_up = fit_models(X_train_up, y_train_up)\n",
        "train_report_up, train_matrix_up = compare_models(_models_up, X_train_up, y_train_up)\n",
        "test_report_up, test_matrix_up = compare_models(_models_up, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0BzT4D5qTao",
        "colab_type": "code",
        "outputId": "6666ecac-8654-40c8-f291-0ffd71da63fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "print_result(models, train_report_up, test_report_up)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN_____________________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.96      0.71      0.82      2029                0       0.87      0.63      0.73       505\n",
            "           1       0.77      0.97      0.86      2029                1       0.19      0.48      0.27        90\n",
            "     \n",
            "    accuracy                           0.84      4058         accuracy                           0.61       595\n",
            "   macro avg       0.87      0.84      0.84      4058        macro avg       0.53      0.55      0.50       595\n",
            "weighted avg       0.87      0.84      0.84      4058     weighted avg       0.77      0.61      0.66       595\n",
            "     \n",
            "SVM_Linear______________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.72      0.68      0.70      2029                0       0.92      0.63      0.75       505\n",
            "           1       0.70      0.74      0.72      2029                1       0.25      0.69      0.36        90\n",
            "     \n",
            "    accuracy                           0.71      4058         accuracy                           0.64       595\n",
            "   macro avg       0.71      0.71      0.71      4058        macro avg       0.58      0.66      0.56       595\n",
            "weighted avg       0.71      0.71      0.71      4058     weighted avg       0.82      0.64      0.69       595\n",
            "     \n",
            "DecisionTree____________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.96      0.94      0.95      2029                0       0.87      0.83      0.85       505\n",
            "           1       0.95      0.96      0.95      2029                1       0.25      0.32      0.28        90\n",
            "     \n",
            "    accuracy                           0.95      4058         accuracy                           0.75       595\n",
            "   macro avg       0.95      0.95      0.95      4058        macro avg       0.56      0.57      0.56       595\n",
            "weighted avg       0.95      0.95      0.95      4058     weighted avg       0.78      0.75      0.76       595\n",
            "     \n",
            "NaiveBayesian___________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.78      0.48      0.59      2029                0       0.90      0.44      0.59       505\n",
            "           1       0.62      0.86      0.72      2029                1       0.18      0.71      0.29        90\n",
            "     \n",
            "    accuracy                           0.67      4058         accuracy                           0.48       595\n",
            "   macro avg       0.70      0.67      0.66      4058        macro avg       0.54      0.58      0.44       595\n",
            "weighted avg       0.70      0.67      0.66      4058     weighted avg       0.79      0.48      0.55       595\n",
            "     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbg0VYF5N8ov",
        "colab_type": "text"
      },
      "source": [
        "Undersampling Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk9m-ogdN9sT",
        "colab_type": "code",
        "outputId": "44749e15-1cd1-4231-d9d6-25721f0086b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "_models_under = fit_models(X_train_under, y_train_under)\n",
        "train_report_under, train_matrix_under = compare_models(_models_under, X_train_under, y_train_under)\n",
        "test_report_under, test_matrix_under = compare_models(_models_under, X_test, y_test)\n",
        "\n",
        "print_result(models, train_report_under, test_report_under)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN_____________________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.72      0.70      0.71       351                0       0.89      0.51      0.65       505\n",
            "           1       0.71      0.73      0.72       351                1       0.19      0.66      0.30        90\n",
            "     \n",
            "    accuracy                           0.72       702         accuracy                           0.53       595\n",
            "   macro avg       0.72      0.72      0.72       702        macro avg       0.54      0.58      0.47       595\n",
            "weighted avg       0.72      0.72      0.72       702     weighted avg       0.79      0.53      0.59       595\n",
            "     \n",
            "SVM_Linear______________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.78      0.71      0.74       351                0       0.93      0.55      0.69       505\n",
            "           1       0.73      0.80      0.77       351                1       0.23      0.76      0.35        90\n",
            "     \n",
            "    accuracy                           0.75       702         accuracy                           0.58       595\n",
            "   macro avg       0.76      0.75      0.75       702        macro avg       0.58      0.65      0.52       595\n",
            "weighted avg       0.76      0.75      0.75       702     weighted avg       0.82      0.58      0.64       595\n",
            "     \n",
            "DecisionTree____________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.95      0.96      0.96       351                0       0.90      0.58      0.70       505\n",
            "           1       0.96      0.95      0.96       351                1       0.21      0.63      0.32        90\n",
            "     \n",
            "    accuracy                           0.96       702         accuracy                           0.59       595\n",
            "   macro avg       0.96      0.96      0.96       702        macro avg       0.55      0.61      0.51       595\n",
            "weighted avg       0.96      0.96      0.96       702     weighted avg       0.79      0.59      0.65       595\n",
            "     \n",
            "NaiveBayesian___________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.74      0.72      0.73       351                0       0.92      0.56      0.70       505\n",
            "           1       0.73      0.75      0.74       351                1       0.22      0.71      0.34        90\n",
            "     \n",
            "    accuracy                           0.74       702         accuracy                           0.58       595\n",
            "   macro avg       0.74      0.74      0.74       702        macro avg       0.57      0.64      0.52       595\n",
            "weighted avg       0.74      0.74      0.74       702     weighted avg       0.81      0.58      0.64       595\n",
            "     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85YNPxUiWUle",
        "colab_type": "text"
      },
      "source": [
        "SMOTE Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX4yFVQHWUFt",
        "colab_type": "code",
        "outputId": "f473c9de-3976-4fe6-cedc-ead810d28fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "_models_SMOTE = fit_models(X_train_SMOTE, y_train_SMOTE)\n",
        "train_report_SMOTE, train_matrix_SMOTE = compare_models(_models_SMOTE, X_train_SMOTE, y_train_SMOTE)\n",
        "test_report_SMOTE, test_matrix_SMOTE = compare_models(_models_SMOTE, X_test, y_test)\n",
        "\n",
        "\n",
        "print_result(models, train_report_SMOTE, test_report_SMOTE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN_____________________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.95      0.67      0.78      2029                0       0.89      0.56      0.69       505\n",
            "           1       0.74      0.97      0.84      2029                1       0.20      0.60      0.30        90\n",
            "     \n",
            "    accuracy                           0.82      4058         accuracy                           0.57       595\n",
            "   macro avg       0.85      0.82      0.81      4058        macro avg       0.54      0.58      0.49       595\n",
            "weighted avg       0.85      0.82      0.81      4058     weighted avg       0.78      0.57      0.63       595\n",
            "     \n",
            "SVM_Linear______________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.77      0.69      0.73      2029                0       0.92      0.65      0.76       505\n",
            "           1       0.72      0.80      0.76      2029                1       0.26      0.68      0.37        90\n",
            "     \n",
            "    accuracy                           0.74      4058         accuracy                           0.66       595\n",
            "   macro avg       0.74      0.74      0.74      4058        macro avg       0.59      0.67      0.57       595\n",
            "weighted avg       0.74      0.74      0.74      4058     weighted avg       0.82      0.66      0.70       595\n",
            "     \n",
            "DecisionTree____________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.97      0.96      0.97      2029                0       0.87      0.85      0.86       505\n",
            "           1       0.96      0.97      0.97      2029                1       0.24      0.27      0.25        90\n",
            "     \n",
            "    accuracy                           0.97      4058         accuracy                           0.76       595\n",
            "   macro avg       0.97      0.97      0.97      4058        macro avg       0.55      0.56      0.56       595\n",
            "weighted avg       0.97      0.97      0.97      4058     weighted avg       0.77      0.76      0.77       595\n",
            "     \n",
            "NaiveBayesian___________________________________________________________________________________________________\n",
            "train                                                           test\n",
            "              precision    recall  f1-score   support                   precision    recall  f1-score   support\n",
            "     \n",
            "           0       0.81      0.56      0.66      2029                0       0.89      0.52      0.66       505\n",
            "           1       0.66      0.87      0.75      2029                1       0.19      0.64      0.30        90\n",
            "     \n",
            "    accuracy                           0.71      4058         accuracy                           0.54       595\n",
            "   macro avg       0.74      0.71      0.71      4058        macro avg       0.54      0.58      0.48       595\n",
            "weighted avg       0.74      0.71      0.71      4058     weighted avg       0.79      0.54      0.61       595\n",
            "     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EUexi1Q5pxY",
        "colab_type": "text"
      },
      "source": [
        "###5.Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmyjF1chnfX-",
        "colab_type": "text"
      },
      "source": [
        "To validate our model, we run cross validation and draw ROC curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TikUc615ObHJ",
        "colab_type": "text"
      },
      "source": [
        "#### 1.Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-jwephaPgaz",
        "colab_type": "text"
      },
      "source": [
        "Since the data is imbalanced, we adopt stratifiedKFold function that keeps class weights on spliiting data for cross validation. Also, we use f1_scorer to compare models by f1_measure, not Accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ggg1_FD2IvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def cross_validation(estimators, folds, X_mat, Y_vec):\n",
        "   for estimator_name, estimator_object in estimators.items():\n",
        "      \n",
        "    f1_scorer = make_scorer(f1_score, pos_label= 1)\n",
        "    kfolds = StratifiedKFold(n_splits=folds, random_state=123, shuffle=True)\n",
        "    scores = cross_val_score(estimator=estimator_object, X=X_mat, y=Y_vec, cv=kfolds, scoring = f1_scorer)\n",
        "    print(f'{estimator_name:>20}: '\n",
        "          f'mean f1={scores.mean():.2%}; ' +\n",
        "          f'standard deviation={scores.std():.2%}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYCl-SPy1JJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = {\n",
        "    'knn': KNeighborsClassifier(),\n",
        "    'svm': SVC(kernel='linear', random_state=123, class_weight = 'balanced'),\n",
        "    'dt': DecisionTreeClassifier(random_state=123),\n",
        "    'nb': GaussianNB()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbxnjr1wuQUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_oversampled = pd.DataFrame(X_train_SMOTE, columns = X_test.columns)\n",
        "oversampled_x = pd.concat([X_test, X_train_oversampled])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rh4lqhVvuKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_oversampled = pd.Series(y_train_SMOTE)\n",
        "oversampled_y = y_test.append(y_train_oversampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA3JJbi9QRSq",
        "colab_type": "text"
      },
      "source": [
        "First, cross validation on oversampled data(Oversampled_training + test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBHIdjNwOJr",
        "colab_type": "code",
        "outputId": "a4c4bed4-d7c8-4693-93e9-95bf3c1cd2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "cross_validation(estimators, 10, oversampled_x, oversampled_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 knn: mean f1=76.73%; standard deviation=2.31%\n",
            "                 svm: mean f1=71.05%; standard deviation=1.61%\n",
            "                  dt: mean f1=81.23%; standard deviation=2.36%\n",
            "                  nb: mean f1=70.92%; standard deviation=1.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH69m4ueQYIL",
        "colab_type": "text"
      },
      "source": [
        "Second, cross validation on Original data(training + test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbe_cxfL1FXw",
        "colab_type": "code",
        "outputId": "cc783c99-fd94-455d-ec26-e6b5bf03a085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "cross_validation(estimators, 10, X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 knn: mean f1=17.79%; standard deviation=6.03%\n",
            "                 svm: mean f1=34.55%; standard deviation=6.22%\n",
            "                  dt: mean f1=23.45%; standard deviation=6.04%\n",
            "                  nb: mean f1=30.07%; standard deviation=2.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBRNW_kkNmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG6G4zgr7oKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_param_selection(X, y, nfolds):\n",
        "  parameter_candidates = [\n",
        "      {'C':[1,10,100,1000], 'kernel':['linear']}\n",
        "  ]\n",
        "  f1_scorer = make_scorer(f1_score, pos_label= 1)\n",
        "  grid_search = GridSearchCV(estimator = SVC(), param_grid = parameter_candidates, cv = nfolds, scoring = f1_scorer)\n",
        "  grid_search.fit(X, y)\n",
        "  grid_search.best_params_\n",
        "  return grid_search.best_params_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIlue1Ut9QlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_optimized = svm_param_selection(X_train_SMOTE, y_train_SMOTE, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-SvDVJl9ayp",
        "colab_type": "code",
        "outputId": "23010c6d-0640-4fda-8aa3-02f9bab3acb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_optimized"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1000, 'kernel': 'linear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPy0PW-Y_zUf",
        "colab_type": "code",
        "outputId": "d6446d59-c1e1-4b7a-dd4e-afa8c303c83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "svm = SVC(kernel = 'linear', C = 1000, random_state = 123)\n",
        "svm.fit(X_train_SMOTE, y_train_SMOTE)\n",
        "_predicted = svm.predict(X = X_test)\n",
        "report = metrics.classification_report(y_test, _predicted)\n",
        "print(report)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.66      0.77       505\n",
            "           1       0.26      0.66      0.37        90\n",
            "\n",
            "    accuracy                           0.66       595\n",
            "   macro avg       0.59      0.66      0.57       595\n",
            "weighted avg       0.82      0.66      0.71       595\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIVmnlQbSBbt",
        "colab_type": "text"
      },
      "source": [
        "#### 2.ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmzQFIvFOvea",
        "colab_type": "text"
      },
      "source": [
        "We looked at the Area Under the Curve (AUC) on a ROC graph to future compare the model performance. SVM outperforms the other models here as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ft4QhcSEVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J4OfouK_xhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [KNeighborsClassifier(), \n",
        "               SVC(kernel='linear', random_state=123, probability=True),\n",
        "               DecisionTreeClassifier(random_state=123),\n",
        "               GaussianNB()]\n",
        "\n",
        "\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "names = ['KNN', 'SVM', 'DT','GausianNB']\n",
        "\n",
        "for idx in range(len(names)):\n",
        "    model = classifiers[idx].fit(X_train_SMOTE, y_train_SMOTE)\n",
        "    yproba = model.predict_proba(X_test)[::,1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "    auc = roc_auc_score(y_test, yproba)\n",
        "    \n",
        "    result_table = result_table.append({'classifiers':names[idx],\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc}, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifplbavBShc2",
        "colab_type": "code",
        "outputId": "b9f437da-2d7d-4a66-d3f0-32ba9e563cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(result_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifiers  ...       auc\n",
            "0         KNN  ...  0.608702\n",
            "1         SVM  ...  0.715259\n",
            "2          DT  ...  0.565886\n",
            "3   GausianNB  ...  0.601980\n",
            "\n",
            "[4 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAjJ8-nzSppA",
        "colab_type": "code",
        "outputId": "2c37f679-99c7-42be-a26b-669cbb83993c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'],\n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}. AUC={:.3f}\".format(result_table.loc[i]['classifiers'] ,result_table.loc[i]['auc']))\n",
        "\n",
        "\n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAGKCAYAAADkN4OIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMf8P10+cUipnBwsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}